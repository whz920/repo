{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 爬虫数据集筛选及保存\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "杭州 2019-01-01 良 73 205 53 72 8 39 0.90 20\n",
      "杭州 2019-01-02 良 90 202 66 90 9 48 0.95 21\n",
      "杭州 2019-01-04 良 79 205 58 83 7 53 1.39 5\n",
      "杭州 2019-01-05 优 31 43 21 27 6 42 1.18 6\n",
      "杭州 2019-01-06 良 55 131 38 51 7 42 1.67 10\n",
      "杭州 2019-01-07 良 55 106 38 58 8 55 1.25 4\n",
      "杭州 2019-01-08 良 64 161 45 62 8 47 1.04 18\n",
      "杭州 2019-01-09 良 66 209 47 66 9 51 1.06 17\n",
      "杭州 2019-01-10 优 36 82 22 31 7 49 0.82 6\n",
      "杭州 2019-01-11 优 26 30 15 21 7 48 0.92 3\n",
      "杭州 2019-01-12 优 39 53 26 37 7 37 1.12 13\n",
      "杭州 2019-01-13 良 84 150 62 86 9 42 1.17 22\n",
      "杭州 2019-01-16 良 84 288 60 90 9 37 0.99 26\n",
      "杭州 2019-01-17 良 81 187 59 97 9 46 0.99 23\n",
      "杭州 2019-01-18 良 91 203 66 117 8 53 1.12 27\n",
      "杭州 2019-01-19 良 92 199 68 119 7 55 1.26 10\n",
      "杭州 2019-01-21 良 73 192 52 84 9 47 0.83 26\n",
      "杭州 2019-01-22 良 92 217 68 110 8 49 1.00 36\n",
      "杭州 2019-01-23 良 95 217 70 116 8 58 1.10 36\n",
      "杭州 2019-01-26 优 49 78 28 50 7 24 0.66 52\n",
      "杭州 2019-01-27 良 60 100 38 68 6 41 0.74 35\n",
      "杭州 2019-01-28 良 92 225 67 107 10 59 0.98 15\n",
      "杭州 2019-01-31 优 39 62 22 37 5 23 0.71 45\n",
      "data saved in  ./data.txt\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# 以前遇到过的函数\n",
    "\n",
    "def build_url(city_coding, year=None, month=None):\n",
    "    \"\"\"\n",
    "    创建网页链接\n",
    "    paramters:\n",
    "        city_coding: 城市名称(英文)\n",
    "        year: 年份\n",
    "        month: 月份\n",
    "    return:\n",
    "        url: 可访问的链接\n",
    "    \"\"\"\n",
    "    BASE = 'http://www.tianqihoubao.com/aqi/'\n",
    "    city_base_url = BASE + '{}.html'\n",
    "    city_date_base_url = BASE + '{}-{}{}.html'\n",
    "    \n",
    "    if year is not None and month is not None:\n",
    "        month = str(month) if month >= 10 else '0' + str(month)\n",
    "        return city_date_base_url.format(city_coding, year, month)\n",
    "    else:\n",
    "        return city_base_url.format(city_coding)\n",
    "\n",
    "\n",
    "def parse(url, city_name):\n",
    "    \"\"\"\n",
    "    抓取网页信息\n",
    "    parameters:\n",
    "        url: 需要抓取的网页链接\n",
    "        city_name: 城市名称(用于数据标识)\n",
    "    returns:\n",
    "        result: 抓取的信息\n",
    "    \"\"\"\n",
    "    response = requests.get(url)\n",
    "    if response.ok:\n",
    "        html = response.text\n",
    "        \n",
    "        soup = BeautifulSoup(html)\n",
    "        data_table = soup.table\n",
    "        \n",
    "        content = data_table.contents\n",
    "        \n",
    "        result = []\n",
    "        for index, c in enumerate(content[1::2]):\n",
    "                if index == 0:\n",
    "                    result.append(tuple(['城市'] + c.text.split()))\n",
    "                else:\n",
    "                    result.append(tuple([city_name] + c.text.split()))\n",
    "        return result\n",
    "    \n",
    "    else:\n",
    "        if response.status_code == 403:\n",
    "            print('403 Forbidden! 抓取太快你被拉黑啦~')\n",
    "\n",
    "            \n",
    "def save(data, file):\n",
    "    # 完成数据保存到文件\n",
    "    # your code here\n",
    "    # 提示：用什么方法将数据写入文件？\n",
    "    with open(file,'w') as f:\n",
    "        f.write(data)\n",
    "    print('data saved in ', file)\n",
    "    #关闭文件\n",
    "    f.close()\n",
    "    \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    datas = []\n",
    "    data1 =''\n",
    "    for i in range(1, 2):\n",
    "        url = build_url('hangzhou', 2019, i)\n",
    "        data = parse(url, '杭州')\n",
    "        datas.extend(data)\n",
    "    #print(datas)\n",
    "    \n",
    "    # 只保留质量等级优 良 数据\n",
    "    # your code here\n",
    "    # 提示：用什么方法对数据进行筛选？\n",
    "    \n",
    "    \n",
    "    #for line in datas:\n",
    "    #    if line[2]== '优'or line[2]=='良':\n",
    "    \n",
    "    filter_data = list(filter(lambda line:line[2]=='优'or line[2]=='良' ,datas))\n",
    "    for line in filter_data:\n",
    "        data1 =  data1 + '\\n' + ' '.join(line)\n",
    "        #data2 = data2 + '\\n' + data1\n",
    "    print (data1)\n",
    "        \n",
    "    # 保存数据\n",
    "    save(data1, './data.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
